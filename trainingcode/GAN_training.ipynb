{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "cudnn.fastest = True\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import datetime\n",
    "from random import randrange, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from data_load_gan import index_group, data_loading\n",
    "from gan_models import D, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Sync/Kun/30_min_ele/non_ele_whole/train/1902_inp.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f5f3b7cf407d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0minput_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;31m#         input_cpu = input_cpu[:,0:3,:,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#         target_cpu = target_cpu[:,0:3,:,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Sync/Kun/DeepFloodPrediction/data_load_gan.py\u001b[0m in \u001b[0;36mdata_loading\u001b[0;34m(index_group, path)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mpath_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_inp.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mpath_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_op.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtemp_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtemp_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtemp_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_ip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Sync/Kun/30_min_ele/non_ele_whole/train/1902_inp.npy'"
     ]
    }
   ],
   "source": [
    "# define the GPU environment\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "# load the area by different classes\n",
    "channel_map = np.load('/home/gtx1080/Abduallah/pix2pix.pytorch/channel_map.npy')\n",
    "channel_map = torch.tensor(channel_map, dtype = torch.float, requires_grad = False)\n",
    "# load the path to training and test data\n",
    "path_train_data = '../../Sync/Kun/30_min_ele/non_ele_whole/train/'\n",
    "path_test_data = '../../Sync/Kun/30_min_ele/non_ele_whole/test/'\n",
    "# path to save trained models\n",
    "path_save = '../../Sync/Kun/0718_newGAN/'\n",
    "\n",
    "# define training details\n",
    "manualSeed = 101\n",
    "inputChannelSize = 5\n",
    "outputChannelSize = 3\n",
    "batchSize = 64\n",
    "imageSize = 100\n",
    "# valBatchSize = \n",
    "print_cost = True\n",
    "# variables that uncertain about\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "lambdaGAN = 1\n",
    "lambdaIMG = 200\n",
    "lambdaIMGp = 100\n",
    "lrD = 0.001\n",
    "lrG = 0.001\n",
    "niter = 1\n",
    "train_num = 10000\n",
    "test_num = 2000\n",
    "latent_dim = 512\n",
    "# record the cost after every epoch\n",
    "costs = []\n",
    "test_costs = []\n",
    "\n",
    "# evalIter = \n",
    "\n",
    "# control the random seed\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "# load the model\n",
    "netG = G()\n",
    "# if opt.netG != '':\n",
    "#   netG.load_state_dict(torch.load(opt.netG))\n",
    "# print(netG)\n",
    "netD = D(inputChannelSize + outputChannelSize, ndf)\n",
    "# if opt.netD != '':\n",
    "#   netD.load_state_dict(torch.load(opt.netD))\n",
    "# print(netD)\n",
    "\n",
    "netG.train()\n",
    "netD.train()\n",
    "\n",
    "# define the loss functions\n",
    "criterionBCE = nn.BCELoss()\n",
    "criterionCAE = nn.L1Loss()\n",
    "# CAEP is to add more weights to the channel part \n",
    "criterionCAEP = nn.L1Loss()\n",
    "\n",
    "target_ = torch.FloatTensor(batchSize, outputChannelSize, imageSize, imageSize)\n",
    "input_ = torch.FloatTensor(batchSize, inputChannelSize, imageSize, imageSize)\n",
    "input_noise = torch.FloatTensor(batchSize, inputChannelSize, imageSize, imageSize)\n",
    "latent_noise = torch.FloatTensor(batchSize, latent_dim, 1, 1)\n",
    "\n",
    "label_d = torch.FloatTensor(batchSize)\n",
    "\n",
    "# NOTE: size of 2D output maps in the discriminator\n",
    "sizePatchGAN = 10\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# NOTE weight for L_cGAN and L_L1 (i.e. Eq.(4) in the paper)\n",
    "netD.cuda()\n",
    "netG.cuda()\n",
    "criterionBCE.cuda()\n",
    "criterionCAE.cuda()\n",
    "criterionCAEP.cuda()\n",
    "\n",
    "target, input_, label_d = target_.cuda(), input_.cuda(), label_d.cuda()\n",
    "latent_noise = latent_noise.cuda()\n",
    "input_noise = input_noise.cuda()\n",
    "\n",
    "target = Variable(target)\n",
    "input_ = Variable(input_)\n",
    "input_noise = Variable(input_noise)\n",
    "latent_noise - Variable(latent_noise)\n",
    "label_d = Variable(label_d)\n",
    "\n",
    "\n",
    "# define the optimizer \n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lrD, betas = (0.9, 0.999), weight_decay=0.0)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lrG, betas = (0.9, 0.999), weight_decay=0.0)\n",
    "channel_map = channel_map.cuda()\n",
    "\n",
    "# NOTE training loop\n",
    "ganIterations = 0\n",
    "train_step = 0\n",
    "for epoch in range(niter):\n",
    "    print(epoch)\n",
    "    epoch_cost = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    train_group, test_group = index_group(batchSize, train_num, test_num)\n",
    "    for batch_id in train_group:\n",
    "        \n",
    "        input_cpu, target_cpu = data_loading(batch_id, path_train_data)\n",
    "#         input_cpu = input_cpu[:,0:3,:,:]\n",
    "#         target_cpu = target_cpu[:,0:3,:,:]\n",
    "        input_cpu = torch.tensor(input_cpu, dtype = torch.float)\n",
    "        target_cpu = torch.tensor(target_cpu, dtype = torch.float)\n",
    "        \n",
    "        batch_size = target_cpu.size(0)\n",
    "\n",
    "        target_cpu, input_cpu = target_cpu.cuda(), input_cpu.cuda()\n",
    "        # NOTE\n",
    "        # default: imgA: target, imgB: input\n",
    "        target.data.resize_as_(target_cpu).copy_(target_cpu)\n",
    "        input_.data.resize_as_(input_cpu).copy_(input_cpu)\n",
    "        input_noise.normal_(0, 0.02)\n",
    "        input_.add_(input_noise) \n",
    "\n",
    "        # max_D first\n",
    "        for p in netD.parameters(): \n",
    "            p.requires_grad = True \n",
    "        netD.zero_grad()\n",
    "        real_label = uniform(0,0.1)\n",
    "        fake_label = uniform(0.9,1.0)\n",
    "        # NOTE: compute L_cGAN in eq.(2)\n",
    "        label_d.data.resize_((batch_size, 1, sizePatchGAN, sizePatchGAN)).fill_(real_label)\n",
    "        output = netD(torch.cat([target, input_], 1)) # conditional\n",
    "        errD_real = criterionBCE(output, label_d)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "#         ae_output_ = netG.Encoder(input_)\n",
    "#         latent_noise.normal_(0, 0.01)\n",
    "#         ae_output_.add_(latent_noise)\n",
    "#         print(ae_output_.shape)\n",
    "        x_hat = netG.forward(input_)\n",
    "        fake = x_hat.detach()\n",
    "        label_d.data.fill_(fake_label)\n",
    "        output = netD(torch.cat([fake, input_], 1)) # conditional\n",
    "        errD_fake = criterionBCE(output, label_d)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step() # update parameters\n",
    "\n",
    "        # prevent computing gradients of weights in Discriminator\n",
    "        for p in netD.parameters(): \n",
    "            p.requires_grad = False\n",
    "        netG.zero_grad() # start to update G\n",
    "\n",
    "        # compute L_L1 (eq.(4) in the paper\n",
    "        L_img_ = criterionCAE(x_hat, target)\n",
    "        L_img = lambdaIMG * L_img_\n",
    "        if lambdaIMG != 0: \n",
    "            L_img.backward(retain_graph=True)\n",
    "\n",
    "        # add more weights on the channel part\n",
    "        x_hatp = x_hat * channel_map\n",
    "        targetp = target * channel_map\n",
    "        L_img_p = criterionCAEP(x_hatp, targetp)\n",
    "        L_imgp = lambdaIMGp * L_img_p\n",
    "        if lambdaIMGp != 0: \n",
    "            L_imgp.backward(retain_graph=True)\n",
    "\n",
    "        # compute L_cGAN (eq.(2) in the paper\n",
    "        label_d.data.fill_(real_label)\n",
    "        output = netD(torch.cat([x_hat, input_], 1))\n",
    "        errG_ = criterionBCE(output, label_d)\n",
    "        errG = lambdaGAN * errG_ \n",
    "        if lambdaGAN != 0:\n",
    "            errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "\n",
    "        optimizerG.step()\n",
    "        \n",
    "        epoch_cost = epoch_cost + L_img_.item()\n",
    "    \n",
    "    # apply the test data\n",
    "    with torch.no_grad():\n",
    "        test_inp, test_op = data_loading(test_group, path_test_data)\n",
    "#         test_inp = test_inp[:,0:3,:,:]\n",
    "#         test_op = test_op[:,0:3,:,:]\n",
    "        test_inp = torch.tensor(test_inp, dtype = torch.float)\n",
    "        test_op = torch.tensor(test_op, dtype = torch.float)\n",
    "        test_inp = test_inp.cuda()\n",
    "        test_op = test_op.cuda()\n",
    "#         temp = netG.Encoder(test_inp)\n",
    "        test_prediction = netG.forward(test_inp)\n",
    "        temp_test_loss = criterionCAE(test_prediction, test_op)\n",
    "        \n",
    "#         temp_test_loss = loss_function(test_prediction, test_op)\n",
    "        test_loss = test_loss + temp_test_loss.item()\n",
    "    \n",
    "    # print the loss value after every several steps of training\n",
    "    if print_cost == True and epoch % 1 == 0:\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch+1, epoch_cost))\n",
    "        print (\"Cost of test after epoch %i: %f\" % (epoch+1, test_loss))\n",
    "        \n",
    "        test_prediction = test_prediction.cpu()\n",
    "        test_prediction = np.array(test_prediction)\n",
    "        save_fig(test_prediction[0,0,:,:], path_save + str(epoch) + '_prediction.jpg')\n",
    "        \n",
    "        test_op = test_op.cpu()\n",
    "        test_op = np.array(test_op)\n",
    "        save_fig(test_op[0,0,:,:], path_save + str(epoch) + '_label.jpg')\n",
    "            \n",
    "    if print_cost == True and epoch % 1 == 0:\n",
    "        costs.append(epoch_cost)\n",
    "        test_costs.append(test_loss)\n",
    "    # save the model result after every several steps\n",
    "  # do checkpointing\n",
    "#     if epoch >= 50 and epoch % 100 == 0:\n",
    "#         torch.save(netG.state_dict(), path_save + str(epoch) + '_modelG.pth')\n",
    "#         torch.save(netD.state_dict(), path_save + str(epoch) + '_modelD.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
