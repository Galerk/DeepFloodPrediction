{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_load_gan import index_group, data_loading\n",
    "from CNN_models import ConvNet_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training code \n",
    "# the path to training data and test data\n",
    "path_train_data = '../../Sync/Kun/30_min_ele/non_ele_whole/train/'\n",
    "path_test_data = '../../Sync/Kun/30_min_ele/non_ele_whole/test/'\n",
    "# the path to save trained models\n",
    "path_save = '../../Sync/Kun/0718CNN_Res/'\n",
    "# number of data\n",
    "train_num = 10000\n",
    "test_num = 2000\n",
    "# training details to be defined\n",
    "batch_size = 196\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "epoches = 8000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# load the deep learning model\n",
    "model = ConvNet_2()\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model).cuda()\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "loss_function = loss_function.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-6)\n",
    "input_noise = torch.FloatTensor(batch_size, 5, 100, 100)\n",
    "input_noise = input_noise.cuda()\n",
    "input_noise = Variable(input_noise)\n",
    "costs = []\n",
    "test_costs = []\n",
    "print_cost = True\n",
    "\n",
    "# schedule for the learning rate\n",
    "lambda1 = lambda epoch: 1/np.sqrt(((epoch % 2000)+1.0))\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda1)\n",
    "\n",
    "# training process\n",
    "for epoch in range(epoches):\n",
    "    print(epoch)\n",
    "    epoch_cost = 0\n",
    "    test_loss = 0\n",
    "    # form the group of training data\n",
    "    train_group, test_group = index_group(batch_size, train_num, test_num)\n",
    "    # start to train by batch\n",
    "    for batch_id in train_group:\n",
    "        \n",
    "        batch_inp, batch_op = data_loading(batch_id, path_train_data)\n",
    "        batch_inp = torch.tensor(batch_inp, dtype = torch.float)\n",
    "        batch_op = torch.tensor(batch_op, dtype = torch.float)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_inp = batch_inp.cuda()\n",
    "        batch_op = batch_op.cuda()\n",
    "        \n",
    "        input_noise.normal_(0, 0.02)\n",
    "        batch_inp.add_(input_noise) \n",
    "        \n",
    "        prediction = model.module.forward(batch_inp)\n",
    "        #print(prediction.shape)\n",
    "        loss = loss_function(prediction, batch_op)   \n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        epoch_cost = epoch_cost + loss.item()\n",
    "    \n",
    "    # test data to check the training performance\n",
    "    with torch.no_grad():\n",
    "        test_inp, test_op = data_loading(test_group, path_test_data)\n",
    "        test_inp = torch.tensor(test_inp, dtype = torch.float)\n",
    "        test_op = torch.tensor(test_op, dtype = torch.float)\n",
    "        test_inp = test_inp.cuda()\n",
    "        test_op = test_op.cuda()\n",
    "        test_prediction = model.module.forward(test_inp)\n",
    "        temp_test_loss = loss_function(test_prediction, test_op)\n",
    "        test_loss = test_loss + temp_test_loss.item()\n",
    "    \n",
    "    # print the training cost and test cost after every several steps\n",
    "    if print_cost == True and epoch % 10 == 0:\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch+1, epoch_cost))\n",
    "        print (\"Cost of test after epoch %i: %f\" % (epoch+1, test_loss))\n",
    "        \n",
    "        test_prediction = test_prediction.cpu()\n",
    "        test_prediction = np.array(test_prediction)\n",
    "        save_fig(test_prediction[0,0,:,:], path_save + str(epoch) + '_prediction.jpg')\n",
    "        \n",
    "        test_op = test_op.cpu()\n",
    "        test_op = np.array(test_op)\n",
    "        save_fig(test_op[0,0,:,:], path_save + str(epoch) + '_label.jpg')\n",
    "    \n",
    "    if print_cost == True and epoch % 5 == 0:\n",
    "        costs.append(epoch_cost)\n",
    "        test_costs.append(test_loss)\n",
    "    # save trained model/parameters after several steps\n",
    "    if epoch >= 50 and epoch % 100 == 0:\n",
    "        torch.save(model, path_save + str(epoch) + '_model')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
