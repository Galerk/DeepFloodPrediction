{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "cudnn.fastest = True\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import models.UNet as net\n",
    "\n",
    "import models.UNet as net_test\n",
    "from misc import *\n",
    "from torchsummary import summary\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from basic_toolfunc import normalization_test, local_area, coord_trans, number_to_coord\n",
    "from model_test_func import prior_update_gan_noise\n",
    "from models.gan_models import G, D\n",
    "\n",
    "class ConvNet_nin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_nin, self).__init__()\n",
    "        # 5*14*14 - 16*12*12\n",
    "        self.convlayer1 = nn.Sequential(\n",
    "            nn.Conv2d(5,196, kernel_size = 16),\n",
    "            nn.BatchNorm2d(196),\n",
    "            nn.PReLU(196))\n",
    "        #self.convlayer1 = nn.DataParallel(self.convlayer1)\n",
    "        \n",
    "#         # 32*12*12 - 64 * 8 * 8\n",
    "        self.convlayer3 = nn.Sequential(\n",
    "            nn.Conv2d(196,24, kernel_size = 12),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.PReLU(24))\n",
    "#         self.convlayer3 = nn.DataParallel(self.convlayer3)\n",
    "        \n",
    "        # 64*8*8 - 32 * 6 * 6\n",
    "        self.convlayer4 = nn.Sequential(\n",
    "            nn.Conv2d(24,3, kernel_size = 4))\n",
    "    def forward(self, x):\n",
    "        x = self.convlayer1(x)\n",
    "        x = self.convlayer3(x)\n",
    "        x = self.convlayer4(x)\n",
    "        return x\n",
    "    \n",
    "def prior_update_gan_noise(particles, inputs, model_no):\n",
    "    netG = net.G(5, 3, 64)\n",
    "    netG.load_state_dict(torch.load('%s/netG_epoch_%d.pth' % ('/home/gtx1080/Abduallah/pix2pix.pytorch/imglog/fluid_noise', model_no)))\n",
    "    netG.eval()\n",
    "    netG.cuda()\n",
    "    mu = np.load('/home/gtx1080/Sync/Kun/30_min_ele/non_ele_whole/train/mu.npy')\n",
    "    var = np.load('/home/gtx1080/Sync/Kun/30_min_ele/non_ele_whole/train/var.npy')\n",
    "    particles = np.concatenate((particles, inputs), axis = 1)\n",
    "    particles, label = normalization_test(particles, particles[:,0:3,:,:], mu, var)\n",
    "    particles = torch.tensor(particles, dtype = torch.float).cuda()\n",
    "    with torch.no_grad():\n",
    "        particles = netG(particles)\n",
    "    particles = np.array(particles.cpu())\n",
    "    particles[:,0,:,:] = particles[:,0,:,:]*np.sqrt(var[5,0]) + mu[5,0]\n",
    "    particles[:,1,:,:] = particles[:,1,:,:]*np.sqrt(var[6,0]) + mu[6,0]\n",
    "    particles[:,2,:,:] = particles[:,2,:,:]*np.sqrt(var[7,0]) + mu[7,0]\n",
    "    particles[:,0,:,:] = np.maximum(particles[:,0,:,:], 0)\n",
    "    return particles\n",
    "\n",
    "def ensemble_learning(states, inputs, gan_no, posgan_no, index_list, point_list_2, cov, obs_var):\n",
    "    # states: present states shape N*3*100*100\n",
    "    # inputs: inputs in the future 30 minutes shape N*2*100*100\n",
    "    # gan_no: the number of trained gan models\n",
    "    # index_list: \n",
    "    # point_list_2: point_list_2\n",
    "    # cov: covariance matrix used: test_cov\n",
    "    # obs_var: the variance of error: [0.000001, 0.0001, 0.0001]\n",
    "    cnnpredictions = meas_data_read(states, inputs, index_list)\n",
    "    ganpredictions = prior_update_gan_noise(states, inputs, gan_no)\n",
    "    cnnpredictions = np.array(cnnpredictions)\n",
    "    \n",
    "    obs_value_list = obs_list_form_hxy(point_list_2, cnnpredictions)\n",
    "    posgan_prediction = two_model_merge(ganpredictions, obs_var, point_list_2, cov, obs_value_list)\n",
    "    posgan_prediction = posgan_prediction.reshape((-1, 3,100,100))\n",
    "    \n",
    "    print(posgan_prediction.shape)\n",
    "    print(inputs.shape)\n",
    "    en_pred_input = np.concatenate((posgan_prediction, inputs), axis = 1)\n",
    "    posposgan_prediction = pos_ensemble_gan_noise(en_pred_input, posgan_no)\n",
    "    \n",
    "    return ganpredictions, posgan_prediction, posposgan_prediction\n",
    "\n",
    "# data assimilation functions\n",
    "def meas_data_read(state, inputs, point_list):\n",
    "    # first do an update with states and input of specific points\n",
    "    # inputs: state, input, the list of points\n",
    "    # return the list of values of specific points\n",
    "    particles = np.concatenate((state, inputs), axis = 1)\n",
    "    \n",
    "    time_series_padded = np.zeros(shape = (particles.shape[0],particles.shape[1],130,130))\n",
    "    time_series_padded[:,:,15:115,15:115] = particles\n",
    "\n",
    "    prediction = []\n",
    "    label = np.zeros((particles.shape[0],3,100,100))\n",
    "\n",
    "    for ele in point_list:\n",
    "#         print(ele)\n",
    "        [index_x, index_y] = ele\n",
    "#         print(index_x)\n",
    "#         print(index_y)\n",
    "#             print((index_x, index_y))\n",
    "\n",
    "        # temp list to save errors\n",
    "        mu_fn = '/home/gtx1080/Sync/Kun/30_min_ele/boundary_para/mu_{0}_{1}.npy'.format(index_x, index_y)\n",
    "        var_fn = '/home/gtx1080/Sync/Kun/30_min_ele/boundary_para/var_{0}_{1}.npy'.format(index_x, index_y)\n",
    "        mu = np.load(mu_fn)\n",
    "        var = np.load(var_fn)\n",
    "\n",
    "        # load the first model\n",
    "        #del model_1\n",
    "        model = torch.load('/home/gtx1080/Sync/Kun/30_min_ele/trained_boundary/trainedmodel_noised_{0}_{1}'.format(index_x, index_y))\n",
    "        model.eval()\n",
    "\n",
    "        # take out the local data\n",
    "        time_series_input_ = time_series_padded[ :, :, index_x+15-15:index_x+15+15, index_y+15-15:index_y+15+15]\n",
    "#             time_series_label_ = time_series[ :, :, index_x, index_y]\n",
    "#             time_series_label_ = time_series_label_.reshape((time_series_label_.shape[0], 3, 1, 1))\n",
    "\n",
    "        # time_series_input_, time_series_label_  = normalization_test(time_series_input_, time_series_label_, test_mu, test_var)\n",
    "        time_series_input_, time_series_label_  = normalization_test(time_series_input_, time_series_input_[:,0:3,:,:], mu, var)\n",
    "        time_series_input_ = torch.tensor(time_series_input_, dtype = torch.float)\n",
    "        time_series_input_ = time_series_input_.cuda()\n",
    "\n",
    "        # del model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_prediction = model.forward(time_series_input_)\n",
    "        test_prediction = test_prediction.cpu()\n",
    "        test_prediction = np.array(test_prediction)\n",
    "\n",
    "        test_prediction[:,0,:,:] = test_prediction[:,0,:,:]*np.sqrt(var[5,0]) + mu[5,0]\n",
    "        test_prediction[:,1,:,:] = test_prediction[:,1,:,:]*np.sqrt(var[6,0]) + mu[6,0]\n",
    "        test_prediction[:,2,:,:] = test_prediction[:,2,:,:]*np.sqrt(var[7,0]) + mu[7,0]\n",
    "\n",
    "#         prediction[:,:,index_x, index_y] = test_prediction[:,:,0,0]\n",
    "        prediction.append(test_prediction[:,:,0,0])\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def obs_list_form(point_list, prediction_array):\n",
    "    # reform the result from function:meas_data_read() to the input to ensemble function\n",
    "    # prediction_array the result form last function (predictions)\n",
    "    # point_list: the list of points(point_list_2)\n",
    "    obs_value_list = []\n",
    "    count = 0\n",
    "    for ele in point_list:\n",
    "        test_x, test_y, label = ele\n",
    "        temp_i = int(count)\n",
    "#         print(temp_i)\n",
    "        if label=='h':\n",
    "            measurement_value = prediction_array[temp_i, :, 0]\n",
    "            obs_value_list.append(measurement_value.copy())\n",
    "        if label=='x':\n",
    "            measurement_value = prediction_array[temp_i, :, 1]\n",
    "            obs_value_list.append(measurement_value.copy())\n",
    "        if label=='y':\n",
    "            measurement_value = prediction_array[temp_i, :, 2]\n",
    "            obs_value_list.append(measurement_value.copy())\n",
    "        count = count + 1\n",
    "    obs_value_list = np.array(obs_value_list)\n",
    "    print(obs_value_list.shape)\n",
    "    obs_value_list = obs_value_list.T.reshape((prediction_array.shape[1],260,-1))\n",
    "    print(prediction_array.shape)\n",
    "    print(obs_value_list.shape)\n",
    "    return obs_value_list\n",
    "\n",
    "def obs_list_form_hxy(point_list, prediction_array):\n",
    "    # prediction_array the result form last function (predictions)\n",
    "    # point_list: the list of points(point_list_2)\n",
    "#     dim = len(point_list)\n",
    "    print(len(point_list))\n",
    "    print(prediction_array.shape)\n",
    "    obs_value_list = []\n",
    "    count = 0\n",
    "    for ele in point_list:\n",
    "        test_x, test_y, label = ele\n",
    "        temp_i = int(count/3)\n",
    "#         print(temp_i)\n",
    "        if label=='h':\n",
    "            measurement_value = prediction_array[temp_i, :, 0]\n",
    "            obs_value_list.append(measurement_value.copy())\n",
    "        if label=='x':\n",
    "            measurement_value = prediction_array[temp_i, :, 1]\n",
    "            obs_value_list.append(measurement_value.copy())\n",
    "        if label=='y':\n",
    "            measurement_value = prediction_array[temp_i, :, 2]\n",
    "            obs_value_list.append(measurement_value.copy())\n",
    "        count = count + 1\n",
    "    obs_value_list = np.array(obs_value_list)\n",
    "#     print(obs_value_list.shape)\n",
    "    obs_value_list = obs_value_list.T.reshape((prediction_array.shape[1],3,-1))\n",
    "#     print(prediction_array.shape)\n",
    "#     print(obs_value_list.shape)\n",
    "    return obs_value_list\n",
    "\n",
    "# the function conduct the posterior update\n",
    "def two_model_merge(temp_gan_prediction, obs_var_list, point_list, test_cov1, obs_value_list):\n",
    "    # temp_gan_prediction: gan_prediction\n",
    "    # obs_var_list = [0.00001, 0.001, 0.001]\n",
    "    # point_list: point_list_2\n",
    "    # test_cov1: test_cov1\n",
    "    # obs_value_list: obs_value_list\n",
    "    gan_shape = temp_gan_prediction.shape\n",
    "    n_sample = gan_shape[0]\n",
    "    obs_num = len(point_list)\n",
    "    obs_ = np.zeros((obs_num,30000))\n",
    "    for i in range(obs_num):\n",
    "        obs_x, obs_y, label = point_list[i]\n",
    "        if label=='h':\n",
    "            index_ = coord_trans(obs_x, obs_y)\n",
    "            obs_[i,index_] = 1.0\n",
    "        if label=='x':\n",
    "            index_ = coord_trans(obs_x, obs_y) + 10000\n",
    "            obs_[i,index_] = 1.0\n",
    "        if label=='y':\n",
    "            index_ = coord_trans(obs_x, obs_y) + 20000\n",
    "            obs_[i,index_] = 1.0\n",
    "\n",
    "    obs_var = np.zeros((obs_num, obs_num))\n",
    "\n",
    "    for i in range(obs_num):\n",
    "        if point_list[i][2] == 'h':\n",
    "            obs_var[i,i] = obs_var_list[0]\n",
    "        if point_list[i][2] == 'x':\n",
    "            obs_var[i,i] = obs_var_list[1]\n",
    "        if point_list[i][2] == 'y':\n",
    "            obs_var[i,i] = obs_var_list[2]\n",
    "    temp_gan_prediction = temp_gan_prediction.reshape((n_sample, 30000)).T\n",
    "    obs_value_list = obs_value_list.reshape((n_sample,obs_num)).T\n",
    "    posgan_prediction = temp_gan_prediction + test_cov1.dot(obs_.T).dot(np.linalg.inv(obs_.dot(test_cov1).dot(obs_.T) + obs_var)).dot(obs_value_list - np.dot(obs_, temp_gan_prediction))\n",
    "    return posgan_prediction\n",
    "\n",
    "def pos_ensemble_gan_noise(inputs, model_no):\n",
    "    netG = net.G(5, 3, 64)\n",
    "    netG.load_state_dict(torch.load('%s/netG_epoch_%d.pth' % ('/home/gtx1080/Abduallah/pix2pix.pytorch/sample', model_no)))\n",
    "    netG.eval()\n",
    "    netG.cuda()\n",
    "    mu = np.load('/home/gtx1080/Sync/Kun/30_min_ele/non_ele_whole/train/mu.npy')\n",
    "    var = np.load('/home/gtx1080/Sync/Kun/30_min_ele/non_ele_whole/train/var.npy')\n",
    "#     particles = np.concatenate((particles, inputs), axis = 1)\n",
    "    inputs, label = normalization_test(inputs, inputs[:,0:3,:,:], mu, var)\n",
    "    inputs = torch.tensor(inputs, dtype = torch.float).cuda()\n",
    "    with torch.no_grad():\n",
    "        inputs = netG(inputs)\n",
    "    inputs = np.array(inputs.cpu())\n",
    "    inputs[:,0,:,:] = inputs[:,0,:,:]*np.sqrt(var[5,0]) + mu[5,0]\n",
    "    inputs[:,1,:,:] = inputs[:,1,:,:]*np.sqrt(var[6,0]) + mu[6,0]\n",
    "    inputs[:,2,:,:] = inputs[:,2,:,:]*np.sqrt(var[7,0]) + mu[7,0]\n",
    "    inputs[:,0,:,:] = np.maximum(inputs[:,0,:,:], 0)\n",
    "    return inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
